
# Machine Learning: Random Forest

## Introducción
- ¿Qué es Machine Learning?
- Diferencias con la estadística tradicional
- Tipos de ML: supervisado, no supervisado, reforzado
- ¿Qué es un modelo de ML? (explicado dentro de los tipos)

## Fundamentos para entender Random Forest
- Concepto de árboles de decisión
- Construcción de un árbol (nodos, hojas, splits)
- Problemas de un árbol de decisión (overfitting, sensibilidad al ruido)
- Estrategias de reducción de features antes del algoritmo (PCA, selección de características, embeddings)

## Random Forest: el siguiente nivel
- Intuición del método (metáfora del consejo de expertos)
- ¿Cómo se construye? (bootstrap, selección de variables)
- Comparación con un solo árbol de decisión
- Ejemplo en ciencias de la vida
- Análisis de features en modelos entrenados: Interpretabilidad con SHAP y Feature Importance

## Evaluación y uso de Random Forest
- ¿Cómo evaluar el modelo? (métricas esenciales sin excesivos detalles)
- Problemas comunes en la evaluación del modelo
  - Sobreentrenamiento y estrategias para evitarlo
  - Bases de datos no balanceadas o inadecuadas
- ¿Cuándo usar y cuándo no usar Random Forest?
- Importancia de variables y su interpretación
- Comparación con modelos lineales y redes neuronales
- Caracterización de la eficiencia del modelo: métricas avanzadas (AUC-ROC, PR-Curve, log-loss, interpretabilidad vs. precisión)

## Conclusión y preguntas
- Resumen de los puntos clave
- Espacio para preguntas y discusión

